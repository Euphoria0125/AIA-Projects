import sys
import os
import torch
import inspect
import numpy as np
import gradio as gr
from importlib import import_module
import open3d as o3d
import glob
import socket
from contextlib import closing

# æ¨¡å‹é…ç½®åº“
MODEL_LIBRARY = {
    "PointConv": {
        "module": "models.pointconv",
        "class": "get_model",
        "init_args": {"num_classes": 40},
        "checkpoint": "/root/autodl-tmp/pointnet/log/pointconv_logs"
    },
    "PointNet++": {
        "module": "models.pointnet2_cls_ssg",
        "class": "get_model",
        "init_args": {"num_class": 40},
        "checkpoint": "/root/autodl-tmp/pointnet/log/pointnet2_logs"
    },
    "DGCNN": {
        "module": "models.DGCNN",
        "class": "DGCNN",
        "init_args": {"output_channels": 40},
        "checkpoint": "/root/autodl-tmp/pointnet/log/dgcnn_logs"
    }
}

# ç³»ç»Ÿåˆå§‹åŒ–
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
current_model = None
model_metadata = {}

def load_model(model_name):
    """æ¨¡å‹åŠ è½½å‡½æ•°"""
    global current_model, model_metadata
    
    if model_name not in MODEL_LIBRARY:
        raise ValueError(f"æœªçŸ¥æ¨¡å‹: {model_name}")
    
    config = MODEL_LIBRARY[model_name]
    
    try:
        module = import_module(config["module"])
        model_class = getattr(module, config["class"])
        
        if inspect.isclass(model_class):
            try:
                current_model = model_class(**config["init_args"])
            except TypeError:
                current_model = model_class()
                if hasattr(current_model, 'set_num_classes'):
                    current_model.set_num_classes(40)
        else:
            current_model = model_class(**config["init_args"])
        
        if os.path.exists(config["checkpoint"]):
            checkpoint_files = sorted(
                glob.glob(f"{config['checkpoint']}/**/best_model.pth", recursive=True),
                key=os.path.getmtime, 
                reverse=True
            )
            if checkpoint_files:
                checkpoint = torch.load(checkpoint_files[0], map_location='cpu')
                state_dict = checkpoint.get('model_state_dict', checkpoint)
                state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
                current_model.load_state_dict(state_dict, strict=False)
        
        model_metadata = {
            'name': model_name,
            'requires_normals': hasattr(current_model, 'normal_channel') and current_model.normal_channel
        }
        
        current_model.eval()
        return f"âœ… {model_name} åŠ è½½æˆåŠŸ"
    
    except Exception as e:
        return f"âŒ åŠ è½½å¤±è´¥: {str(e)}"

def predict(point_cloud, model_name):
    """é¢„æµ‹å‡½æ•°"""
    global current_model
    
    if current_model is None or model_metadata.get('name') != model_name:
        load_model(model_name)
    
    try:
        with open(point_cloud.name, 'r') as f:
            content = f.read()
        
        content = content.replace(',', ' ')
        points = np.fromstring(content, sep=' ').astype(np.float32)
        
        if points.size % 3 != 0:
            raise ValueError("ç‚¹äº‘æ•°æ®ç‚¹æ•°ä¸æ˜¯3çš„å€æ•°")
        points = points.reshape(-1, 3)
        
        if model_metadata['requires_normals'] and points.shape[1] == 3:
            normals = np.zeros((points.shape[0], 3))
            normals[:, 2] = 1
            points = np.hstack([points, normals])
        elif not model_metadata['requires_normals'] and points.shape[1] > 3:
            points = points[:, :3]
        
        centroid = np.mean(points[:, :3], axis=0)
        points[:, :3] -= centroid
        scale = np.max(np.sqrt(np.sum(points[:, :3]**2, axis=1)))
        if scale > 0:
            points[:, :3] /= scale
        
        points = torch.tensor(points).float().unsqueeze(0).transpose(2, 1)
        
        with torch.no_grad():
            output = current_model(points)
            
            if isinstance(output, tuple):
                pred = output[0]
            elif isinstance(output, dict):
                pred = output.get('logits', output.get('pred_logits', output))
            else:
                pred = output
            
            if pred.dim() == 1:
                pred = pred.unsqueeze(0)
            
            pred_label = torch.argmax(pred, dim=1).item()
        
        return f"æ¨¡å‹: {model_name}\né¢„æµ‹ç±»åˆ«: {pred_label}"
    
    except Exception as e:
        return f"âŒ é¢„æµ‹å¤±è´¥: {str(e)}"
    
def estimate_radius(pcd, k=10):
    distances = pcd.compute_nearest_neighbor_distance()
    avg_dist = np.mean(distances)
    return avg_dist

def create_point_cloud_file(point_cloud):
    """åˆ›å»ºä¸‰è§’ç½‘æ ¼PLYæ–‡ä»¶ä»¥æ”¯æŒ3DæŸ¥çœ‹å™¨"""
    try:
        # è¯»å–æ•°æ®
        with open(point_cloud, 'r') as f:
            content = f.read().replace(',', ' ').replace('\t', ' ')
        
        # è§£ææ•°æ®
        points = np.fromstring(content, sep=' ').astype(np.float32)
        if points.size % 3 != 0:
            raise ValueError("ç‚¹äº‘æ•°æ®ç‚¹æ•°ä¸æ˜¯3çš„å€æ•°")
        points = points.reshape(-1, 3)
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = "/tmp/gradio_pointclouds"
        os.makedirs(temp_dir, exist_ok=True)
        
        # è®¾ç½®è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆä½¿ç”¨å¸¦é¢ç»“æ„çš„ PLY æ–‡ä»¶ï¼‰
        output_filename = os.path.join(temp_dir, f"{os.path.basename(point_cloud)}_mesh.ply")

        # åˆ›å»ºç‚¹äº‘å¯¹è±¡
        pcd = o3d.geometry.PointCloud()
        pcd.points = o3d.utility.Vector3dVector(points)
        pcd.paint_uniform_color([0.8, 0.8, 0.8])  # ç°è‰²
        pcd = pcd.voxel_down_sample(voxel_size=0.005)
        pcd.remove_statistical_outlier(nb_neighbors=20, std_ratio=2.0)
        pcd = pcd.voxel_down_sample(voxel_size=0.005)  

        # ä¼°ç®—æ³•çº¿ï¼ˆå¿…è¦ï¼‰
        pcd.estimate_normals(
            search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.01, max_nn=30)
        )

        # æ›¿æ¢ Poisson ä¸º Ball Pivotingï¼ˆé€‚åˆç¨€ç–ç‚¹äº‘ï¼‰
        radii = [estimate_radius(pcd) * 1.5]
        mesh = o3d.geometry.TriangleMesh.create_from_point_cloud_ball_pivoting(
            pcd, o3d.utility.DoubleVector(radii)
        )

        # ä¿å­˜ä¸‰è§’ç½‘æ ¼ï¼ˆPLYï¼‰
        o3d.io.write_triangle_mesh(output_filename, mesh)

        return output_filename

    except Exception as e:
        raise gr.Error(f"åˆ›å»ºä¸‰è§’ç½‘æ ¼å¤±è´¥: {str(e)}")

def handle_upload(file, model_name):
    """å¢å¼ºçš„ä¸Šä¼ å¤„ç†å‡½æ•°"""
    try:
        # é¢„æµ‹
        prediction = predict(file, model_name)
        
        # å¯è§†åŒ–
        model_path = create_point_cloud_file(file)
        
        # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"ç”Ÿæˆçš„æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        
        # éªŒè¯æ–‡ä»¶å¤§å°
        if os.path.getsize(model_path) == 0:
            raise ValueError("ç”Ÿæˆçš„æ–‡ä»¶ä¸ºç©º")
            
        return prediction, model_path
        
    except Exception as e:
        error_msg = f"å¤„ç†å¤±è´¥: {str(e)}"
        print(error_msg)  # æ§åˆ¶å°æ—¥å¿—
        return error_msg, None
    
import atexit
import shutil

# ç¨‹åºé€€å‡ºæ—¶æ¸…ç†ä¸´æ—¶æ–‡ä»¶
@atexit.register
def cleanup():
    temp_dir = "/tmp/gradio_pointclouds"
    if os.path.exists(temp_dir):
        shutil.rmtree(temp_dir)

# åˆ›å»ºç•Œé¢
with gr.Blocks(title="ç‚¹äº‘åˆ†ç±»æ¨¡å‹åˆ‡æ¢æ¼”ç¤º") as demo:
    gr.Markdown("## ğŸ”„ ç‚¹äº‘åˆ†ç±»æ¨¡å‹åˆ‡æ¢ç³»ç»Ÿ")
    
    with gr.Row():
        model_selector = gr.Dropdown(
            choices=list(MODEL_LIBRARY.keys()),
            value="PointConv",
            label="é€‰æ‹©æ¨¡å‹æ¶æ„"
        )
        upload_box = gr.File(
            label="ä¸Šä¼ ç‚¹äº‘æ–‡ä»¶",
            file_types=[".txt"],
            type="filepath"
        )
    
    with gr.Row():
        status = gr.Textbox(label="æ¨¡å‹çŠ¶æ€", interactive=False)
        result = gr.Textbox(label="é¢„æµ‹ç»“æœ", interactive=False)
        # å°† Image ç»„ä»¶æ›´æ”¹ä¸º Model3D ç»„ä»¶ä»¥å®ç°äº¤äº’å¼æŸ¥çœ‹
        viewer = gr.Model3D(
            label="ç‚¹äº‘3Däº¤äº’å¼å¯è§†åŒ–",
            clear_color=[0.0, 0.0, 0.0, 0.0],
            zoom_speed=1.0,  # è°ƒæ•´ç¼©æ”¾é€Ÿåº¦
            height=500  # å›ºå®šé«˜åº¦
        )
    
    model_selector.change(
        fn=load_model,
        inputs=model_selector,
        outputs=status
    )
    
    upload_box.change(
        fn=handle_upload,
        inputs=[upload_box, model_selector],
        outputs=[result, viewer]
    )

def find_available_port(start_port=7860, end_port=8000):
    """å¯»æ‰¾å¯ç”¨ç«¯å£"""
    for port in range(start_port, end_port + 1):
        with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as s:
            try:
                s.bind(('0.0.0.0', port))
                return port
            except OSError:
                continue
    raise OSError(f"No available ports between {start_port}-{end_port}")

if __name__ == "__main__":
    # åˆå§‹åŒ–é»˜è®¤æ¨¡å‹
    load_model("PointConv")
    
    # è·å–ç«¯å£å¹¶å¯åŠ¨
    port = find_available_port()
    print(f"â³ æ­£åœ¨å¯åŠ¨æœåŠ¡ï¼Œè¯·è®¿é—®: http://localhost:{port}")
    
    # ç¦ç”¨åˆ†æè¯·æ±‚ä»¥é¿å…è¶…æ—¶é”™è¯¯
    os.environ["GRADIO_ANALYTICS_ENABLED"] = "False"
    
    demo.launch(
        server_name="0.0.0.0",
        server_port=port,
        share=False,
        show_error=True
    )